{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import tensorflow_addons as tfa\n","from kaggle_datasets import KaggleDatasets\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import re\n","import PIL\n","import os\n","import shutil\n","import cv2\n","import math\n","import random\n","\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Device:', tpu.master())\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","except:\n","    strategy = tf.distribute.get_strategy()\n","print('Number of replicas:', strategy.num_replicas_in_sync)\n","\n","AUTO = tf.data.experimental.AUTOTUNE\n","print(tf.__version__)"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BASE_PATH = '../input/gan-getting-started'\n","MONET_PATH = os.path.join(BASE_PATH, 'monet_jpg')\n","PHOTO_PATH = os.path.join(BASE_PATH, 'photo_jpg')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x=10\n","def load_images(paths):\n","    images = []\n","    for img in paths:\n","        try:\n","            img = cv2.imread(img)\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        except:\n","            print(\"Could not load {}\".format(img))\n","        images.append(img)\n","    return images"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MONET_IMAGES = [os.path.join(MONET_PATH, file) for file in os.listdir(MONET_PATH)]\n","monet_images = load_images(MONET_IMAGES)\n","\n","PHOTO_IMAGES = [os.path.join(PHOTO_PATH, file) for file in os.listdir(PHOTO_PATH)]\n","photo_images = load_images(PHOTO_IMAGES)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GCS_PATH = KaggleDatasets().get_gcs_path(\"gan-getting-started\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Size of input data\n","MONET_FILES = tf.io.gfile.glob(str(GCS_PATH + '/monet_tfrec/*.tfrec'))\n","PHOTO_FILES = tf.io.gfile.glob(str(GCS_PATH + '/photo_tfrec/*.tfrec'))\n","\n","n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in MONET_FILES]\n","n_monet = np.sum(n)\n","n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in PHOTO_FILES]\n","n_photo = np.sum(n)\n","\n","print(f'Monet image files: {n_monet}')\n","print(f'Photo image files: {n_photo}')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_tfrecord(example):\n","    IMAGE_SIZE = [256, 256]\n","    tfrecord_format = {\n","        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        \"target\": tf.io.FixedLenFeature([], tf.string)\n","    }\n","    example = tf.io.parse_single_example(example, tfrecord_format)\n","    im = example['image']\n","    \n","    image = tf.image.decode_jpeg(im, channels=3)\n","    image = (tf.cast(image, tf.float32) / 127.5) - 1\n","    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n","    \n","    return image\n","def augment_image(image): # input data augmentation\n","    x = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    y = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    \n","    if y > .5: # random crop image\n","        image = tf.image.resize(image, [286, 286])\n","        image = tf.image.random_crop(image, size=[256, 256, 3])\n","            \n","    if x > .6: # random flip image\n","        image = tf.image.random_flip_left_right(image)\n","    \n","    return image"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_data(filenames):\n","    dataset = tf.data.TFRecordDataset(filenames)\n","    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n","    return dataset\n","\n","def gan_dataset(monet_files, photo_files, augment=None, repeat=True, shuffle=True, batch_size=1):\n","    monet_ds = load_data(monet_files)\n","    photo_ds = load_data(photo_files)\n","    \n","    if augment:\n","        monet_ds = monet_ds.map(augment, num_parallel_calls=AUTO)\n","        photo_ds = photo_ds.map(augment, num_parallel_calls=AUTO)\n","    if repeat:\n","        monet_ds = monet_ds.repeat()\n","        photo_ds = photo_ds.repeat()\n","\n","    monet_ds = monet_ds.batch(batch_size, drop_remainder=True)\n","    photo_ds = photo_ds.batch(batch_size, drop_remainder=True)\n","\n","    monet_ds = monet_ds.prefetch(AUTO)\n","    photo_ds = photo_ds.prefetch(AUTO)\n","    \n","    gan_ds = tf.data.Dataset.zip((monet_ds, photo_ds))\n","    \n","    return gan_ds\n","data = gan_dataset(MONET_FILES, PHOTO_FILES, augment=augment_image, repeat=True, shuffle=True, batch_size=4)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def augment_image(image): # input data augmentation\n","    x = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    y = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n","    \n","    if y > .5: # random crop image\n","        image = tf.image.resize(image, [286, 286])\n","        image = tf.image.random_crop(image, size=[256, 256, 3])\n","            \n","    if x > .6: # random flip image\n","        image = tf.image.random_flip_left_right(image)\n","    \n","    return image"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_monet , sample_photo = next(iter(data))\n","\n","# Display Photo images\n","plt.subplot(121)\n","plt.title('Photo')\n","plt.imshow(sample_photo[0] * 0.5 + 0.5)\n","\n","# Display Monet images\n","plt.subplot(122)\n","plt.title('Monet')\n","plt.imshow(sample_monet[0] * 0.5 + 0.5)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def down_sample(filters, size, apply_instancenorm=True):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n","\n","    layer = keras.Sequential()\n","    layer.add(layers.Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n","\n","    if apply_instancenorm:\n","        layer.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n","\n","    layer.add(layers.LeakyReLU())\n","\n","    return layer\n","\n","def up_sample(filters, size, apply_dropout=False):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n","\n","    layer = keras.Sequential()\n","    layer.add(layers.Conv2DTranspose(filters, size, strides=2, padding='same', kernel_initializer=initializer,use_bias=False))\n","    layer.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n","\n","    if apply_dropout:\n","        layer.add(layers.Dropout(0.5))\n","\n","    layer.add(layers.ReLU())\n","\n","    return layer"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generator():\n","    inputs = layers.Input(shape=[256,256,3])\n","    down_stack = [\n","        down_sample(64, 4, apply_instancenorm=False),# (size, 128, 128, 64)\n","        down_sample(128, 4),                         # (size, 64, 64, 128)\n","        down_sample(256, 4),                         # (size, 32, 32, 256)\n","        down_sample(512, 4),                         # (size, 16, 16, 512)\n","        down_sample(512, 4),                         # (size, 8, 8, 512)\n","        down_sample(512, 4),                         # (size, 4, 4, 512)\n","        down_sample(512, 4),                         # (size, 2, 2, 512)\n","        down_sample(512, 4),                         # (size, 1, 1, 512)\n","    ]\n","\n","    up_stack = [\n","        up_sample(512, 4, apply_dropout=True),       # (size, 2, 2, 1024)\n","        up_sample(512, 4, apply_dropout=True),       # (size, 4, 4, 1024)\n","        up_sample(512, 4, apply_dropout=True),       # (size, 8, 8, 1024)\n","        up_sample(512, 4),                           # (size, 16, 16, 1024)\n","        up_sample(256, 4),                           # (size, 32, 32, 512)\n","        up_sample(128, 4),                           # (size, 64, 64, 256)\n","        up_sample(64, 4),                            # (size, 128, 128, 128)\n","    ]\n","\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    last = layers.Conv2DTranspose(3, 4, strides=2, padding='same', kernel_initializer=initializer, activation='tanh') \n","    # (size, 256, 256, 3)\n","\n","    x = inputs\n","\n","    # Downsampling through the model\n","    skips = []\n","    for down in down_stack:\n","        x = down(x)\n","        skips.append(x)\n","\n","    skips = reversed(skips[:-1])\n","\n","    # Upsampling and establishing the skip connections\n","    for up, skip in zip(up_stack, skips):\n","        x = up(x)\n","        x = layers.Concatenate()([x, skip])\n","\n","    x = last(x)\n","\n","    return keras.Model(inputs=inputs, outputs=x)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def discriminator():\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n","    \n","    inp = layers.Input(shape=[256, 256, 3], name='input_image')\n","    x = inp\n","    \n","    down1 = down_sample(64, 4, False)(x)       # (size, 128, 128, 64)\n","    down2 = down_sample(128, 4)(down1)         # (size, 64, 64, 128)\n","    down3 = down_sample(256, 4)(down2)         # (size, 32, 32, 256)\n","\n","    zero_pad1 = layers.ZeroPadding2D()(down3) # (size, 34, 34, 256)\n","    conv = layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad1) # (size, 31, 31, 512)\n","\n","    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(conv)\n","    leaky_relu = layers.LeakyReLU()(norm1)\n","    zero_pad2 = layers.ZeroPadding2D()(leaky_relu) # (size, 33, 33, 512)\n","    last = layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2) # (size, 30, 30, 1)\n","\n","    return tf.keras.Model(inputs=inp, outputs=last)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with strategy.scope(): # for TPU\n","    monet_generator = generator() # transforms photos to Monet paintings\n","    photo_generator = generator() # transforms Monet paintings to be more like photos\n","\n","    monet_discriminator = discriminator() # differentiates real Monet paintings and generated Monet paintings\n","    photo_discriminator = discriminator()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Gan(keras.Model):\n","    def __init__(\n","        self,\n","        monet_generator,\n","        photo_generator,\n","        monet_discriminator,\n","        photo_discriminator,\n","        lambda_cycle=150,\n","    ):\n","        super(Gan, self).__init__()\n","        self.m_gen = monet_generator\n","        self.p_gen = photo_generator\n","        self.m_disc = monet_discriminator\n","        self.p_disc = photo_discriminator\n","        self.lambda_cycle = lambda_cycle\n","        \n","    def compile(\n","        self,\n","        m_gen_optimizer,\n","        p_gen_optimizer,\n","        m_disc_optimizer,\n","        p_disc_optimizer,\n","        gen_loss_fn,\n","        disc_loss_fn,\n","        cycle_loss_fn,\n","        identity_loss_fn\n","    ):\n","        super(Gan, self).compile()\n","        self.m_gen_optimizer = m_gen_optimizer\n","        self.p_gen_optimizer = p_gen_optimizer\n","        self.m_disc_optimizer = m_disc_optimizer\n","        self.p_disc_optimizer = p_disc_optimizer\n","        self.gen_loss_fn = gen_loss_fn\n","        self.disc_loss_fn = disc_loss_fn\n","        self.cycle_loss_fn = cycle_loss_fn\n","        self.identity_loss_fn = identity_loss_fn\n","        \n","    def train_step(self, batch_data):\n","        real_monet, real_photo = batch_data\n","        \n","        with tf.GradientTape(persistent=True) as tape:\n","            fake_monet = self.m_gen(real_photo, training=True)\n","            same_monet = self.m_gen(real_monet, training=True)\n","            disc_real_monet = self.m_disc(real_monet, training=True)\n","            disc_fake_monet = self.m_disc(fake_monet, training=True)\n","            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n","            total_monet_gen_loss = monet_gen_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n","            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)      \n","            \n","        monet_generator_gradients = tape.gradient(total_monet_gen_loss, self.m_gen.trainable_variables)\n","\n","        monet_discriminator_gradients = tape.gradient(monet_disc_loss, self.m_disc.trainable_variables)\n","        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients, self.m_gen.trainable_variables))\n","        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients, self.m_disc.trainable_variables))\n","        \n","        return {\n","            \"monet_gen_loss\": total_monet_gen_loss,\n","            \"monet_disc_loss\": monet_disc_loss,\n","        }"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with strategy.scope(): # for TPU\n","    def discriminator_loss(real, generated):\n","        real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(real), real)\n","        generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n","        total_disc_loss = real_loss + generated_loss\n","\n","        return total_disc_loss * 0.5\n","\n","with strategy.scope(): # for TPU\n","    def generator_loss(generated):\n","        return tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(generated), generated)\n","\n","with strategy.scope(): # for TPU\n","    def calculate_cycle_loss(real_image, cycled_image, LAMBDA):\n","        loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n","        return LAMBDA * loss1\n","\n","with strategy.scope(): # for TPU\n","    def identity_loss(real_image, same_image, LAMBDA):\n","        loss = tf.reduce_mean(tf.abs(real_image - same_image))\n","        return LAMBDA * 0.5 * loss"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with strategy.scope(): # for TPU\n","    monet_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","    photo_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","\n","    monet_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with strategy.scope(): # for TPU\n","    gan_model = Gan(monet_generator, photo_generator, monet_discriminator, photo_discriminator)\n","\n","    gan_model.compile(\n","        m_gen_optimizer = monet_generator_optimizer,\n","        p_gen_optimizer = photo_generator_optimizer,\n","        m_disc_optimizer = monet_discriminator_optimizer,\n","        p_disc_optimizer = photo_discriminator_optimizer,\n","        gen_loss_fn = generator_loss,\n","        disc_loss_fn = discriminator_loss,\n","        cycle_loss_fn = calculate_cycle_loss,\n","        identity_loss_fn = identity_loss\n","    )"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gan_model.fit(data, epochs=25, steps_per_epoch=(max(n_monet, n_photo)//5))"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_and_save(input_ds, generator_model, output_path):\n","    i = 1\n","    for img in input_ds:\n","        prediction = generator_model(img, training=False)[0].numpy() # make predition\n","        prediction = (prediction * 127.5 + 127.5).astype(np.uint8)   # re-scale\n","        im = PIL.Image.fromarray(prediction)\n","        im.save(f'{output_path}{str(i)}.jpg')\n","        i += 1"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.makedirs('../images/')\n","predict_and_save(load_data(PHOTO_FILES).batch(1), monet_generator, '../images/')\n","shutil.make_archive('/kaggle/working/images/', 'zip', '../images')\n","print(f\"Generated samples: {len([name for name in os.listdir('../images/') if os.path.isfile(os.path.join('../images/', name))])}\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["monet_histograms = [[cv2.calcHist([image],[i],None,[256],[0,256]) for i in range(3)] for image in monet_images]\n","photo_histograms = [[cv2.calcHist([image],[i],None,[256],[0,256]) for i in range(3)] for image in photo_images]"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_histograms(img, title):\n","    plt.figure(figsize=(16,16))\n","    \n","    plt.title(title)\n","    color = ('b','g','r')\n","    \n","    \n","    w = 4\n","    h = int(len(img)/2)\n","    \n","    idxs = [i for i in range(len(img)*2)[::2]]\n","    \n","    for idx, image in zip(idxs,img):\n","        \n","        plt.subplot(h, w, idx + 1)\n","        plt.imshow(image)\n","        plt.axis('off')\n","        \n","        plt.subplot(h, w, idx + 2)\n","        for i,col in enumerate(color):   \n","            histr = cv2.calcHist([image],[i],None,[256],[0,256])\n","            plt.plot(histr,color = col)\n","            plt.xlim([0,256])"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_histograms(random.sample(monet_images,8), \"Histogram for Monet Image\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_histograms(random.sample(photo_images,8), \"Histogram for Photo\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["color = ('b','g','r')\n","monet_means = {c: [np.mean(x[:,:,i]) for x in monet_images] for i,c in enumerate(color)}\n","photo_means = {c: [np.mean(x[:,:,i]) for x in photo_images] for i,c in enumerate(color)}\n","\n","monet_std = {c: [np.std(x[:,:,i]) for x in monet_images] for i,c in enumerate(color)}\n","photo_std = {c: [np.std(x[:,:,i]) for x in photo_images] for i,c in enumerate(color)}"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def boxplots_for_comparison(monet, photo, title):\n","    for i,c in enumerate(color):\n","        fig, ax = plt.subplots()\n","        ax.set_title('{} Channel: {}'.format(c.upper(), title))\n","        ax.boxplot([monet[c], photo[c]])\n","        ax.set_xticklabels([\"Monet\",\"Photo\"])\n","        fig.show()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["boxplots_for_comparison(monet_means, photo_means, \"Pixel Value Mean comparison - Monet and Photo\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["boxplots_for_comparison(monet_std, photo_std, \"Pixel Value standard deviation comparison - Monet and Photo\")"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["zero_values_monet = {c: [np.count_nonzero(hist[i].ravel()==0) for hist in monet_histograms] for i,c in enumerate(color)}\n","zero_values_photo = {c: [np.count_nonzero(hist[i].ravel()==0) for hist in photo_histograms] for i,c in enumerate(color)}"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["boxplots_for_comparison(zero_values_monet,zero_values_photo, \"Number of not used intensity values Monet and Photo\" )"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{}}]}